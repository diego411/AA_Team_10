\documentclass{article}
\usepackage{graphicx} % für Bilder
\usepackage[utf8]{inputenc} % für Umlaute
\usepackage{amsmath} % für mathematische Formeln
\usepackage{amsthm} % für Theorem-Umgebungen
\usepackage{amssymb} % für Sonderzeichen wie ∀ (für "für alle")
\usepackage{amsfonts}
\usepackage{setspace}
\usepackage{fontsize}

\fontsize{12pt}{14pt} % 12pt Schriftgröße, 14pt Zeilenabstand
\selectfont
\begin{document}

\begin{titlepage}
  \centering
  \textsc{\Large \textbf{Using real-time data to monitor and optimize fleet operations}}\\[1cm]
  \textsc{\large \textbf{Group:} Team zehn}\\[0.5cm]
  \textsc{\large \textbf{Members:} Ercan Tazegül, Simon Knecht, Diego , Marc Asbach, Vicent Sedaletec}\\[0.5cm]
    \textsc{\large \textbf{Instructor:} Prof. Dr. Wolfgang Ketter, Nastaran Naseri}\\[0.5cm]
  \textsc{\large \textbf{Subject:} Analytics and Application}\\[1cm]
  \includegraphics[width=0.7\textwidth]{Uni.png}\\[3cm]
    \textsc{\large University of Cologne}\\[0.5cm]
  \textsc{\large 31.01.2022}\\[0.5cm]
  \vfill
  \vfill
\end{titlepage}

\newpage
\tableofcontents
\listoftables
\listoffigures
\newpage
\section{Summary}
The objective of this project is to study the 2018 Divvy Bikes Chicago bike ride dataset, which comprises two datasets: one containing data on Chicago bike rentals in 2018, and the other containing hourly weather data for 2018 obtained through the weather.com API. In order to understand and optimize the performance of the bike fleet, we have defined key performance indicators (KPIs) and analyzed the datasets for temporal and spatial demand patterns. Cluster analysis was used to identify recurring patterns and inform business decision-making. Furthermore, we have applied predictive analysis techniques, such as scientific forecasting models, to forecast future demand and optimize operations.

\newpage
\section{Problem Description}
Transport-related greenhouse gas emissions account for a large share of total emissions in the EU, and it is widely recognized that our approach to mobility needs to change in order to achieve our decarbonization goals. Traditional urban mobility is mainly based on internal combustion engine vehicles, which have four negative impacts: Contribution to global greenhouse gas emissions, pollution with serious health risks for urban populations, high accident rate with nearly 1.3 million fatal accidents annually worldwide, and inefficient use of motor vehicles with low occupancy and high space requirements for roads and parking, and traffic congestion. The need for a major transformation of the mobility system has been recognized, and the mobility landscape is changing rapidly, with the important trend of Mobility-as-a-Service (MaaS) and On-Demand (MoD), as well as the use of bikesharing platforms and similar platforms for other modes such as cars, mopeds, and e-scooters. 
This project examines 2018 data from the fleet operator of bike-sharing company Divvy Bikes Chicago. Real-time data streams are used to monitor and optimize operations, increase profitability, and improve service levels. The goal is to demonstrate that Data Science can benefit society. To this end, two core aspects are focused on. The first core aspect is system monitoring to make sustainable and profitable business and operational decisions. The second core aspect is demand forecasting to improve service levels by repositioning bikes or providing additional bikes. The objective is to optimize bike-sharing for sustainability and efficiency, enabling urban populations to utilize the mode of transportation for their commuting needs, thus reducing air pollution in cities and promoting sustainable living.
\newpage
\section{Data Collection and Preparation}
\subsection{Bikesharing Data}
The dataset contains bike sharing data from Divvy Bikes Chicago from 2018. The overview of the variables in the dataset can be seen in Table 1. 
\begin{table}[h]
\caption{Description of bikeshare dataset columns}
\begin{tabular}{|l|c|l|}
  \hline
\textbf{Variable name} & \textbf{Format } & \textbf{Description }\\[0.2cm]
  \hline
start time& datetime & Day and time trip started \\
  \hline
end time & datetime & Day and time trip ended\\
  \hline
start station id  & int & Unique ID of station where trip originated\\
  \hline
end station id& int& Unique ID of station where trip terminated\\
  \hline
start station name  & name& str Name of station where trip originated\\
  \hline
end station name  & name &  str Name of station where trip terminated \\
  \hline  
bike id   & int & Unique ID attached to each bike \\
  \hline  
user type  & User  & membership type \\
  \hline  
\end{tabular}
\end{table}

In the preprocessing phase of the data, we first eliminated duplicate entries by keeping only the last occurrence and discarding the first. Then we filtered out cases where the starttime was later than the endtime. We also ensured that each stationname was uniquely associated with a single stationid and vice versa, and that the maximum number of stationid associated with a single stationname and vice versa did not exceed 1. To merge cases where a single starting station name was associated with multiple starting station IDs (and vice versa), we implemented a merging procedure. We then calculated the average duration and the total duration of all trips, including the 0.999 quantile of trip times to mitigate the effects of unrealistic outliers. Finally, we added two new columns to the data: 'nextride' and 'nextbike', which indicate whether a particular bike ID is used during a given period, and the identity of the next ride for each bike, respectively. After that, we still included the trips that occurred before and after. 
\subsection{Geological Data}
\subsection{Wheater Data}
\begin{table}[h]
The weather data is provided by the wheater.com API and contains the variables listed in Table 2.
\caption{Description of weather dataset columns}

\begin{tabular}{|l|c|l|}
  \hline
\textbf{Variable name} & \textbf{Format } & \textbf{Description }\\[0.2cm]
  \hline
date time& datetime &Day and time of measurement\\
  \hline
max temp & float & Maximum temperature recorded in degC\\
  \hline
min temp & float& Minimum temperature recorded in degC\\
  \hline
precip & int& Binary indicator for precipitation (1=yes,0=no)\\
  \hline 

\end{tabular}
\end{table}
In order to improve the quality of the weather data, we removed all rows containing NaN values. The hottest and coolest temperatures recorded in the dataset appeared to be reasonable, so no further removal was necessary. We then identified 1328 duplicates in the dataset and decided to retain only the last recorded entry for duplicates, as this is generally considered the most reliable in such situations. There were also several rows with data for the same time, so we chose to take the average and remove the duplicates. The earliest recorded date in 2018 was January 1 at midnight, while the latest was December 31 at 11pm. During this time period, 623 hours of data were missing, which is almost 26 days. Ultimately, we decided to estimate the missing data and found that there are missing data every month, distributed throughout the year. There are only a few sequences that are longer than 1, with a maximum length of 6. In the worst case, we therefore do not have data for a period of 6 hours. Taking into account the above arguments, we have decided that it should be possible to estimate the weather for the missing data without making overly inaccurate estimates.
\newpage
\section{Descriptive Analysis}
\subsection{Bikesharing Data}
\subsection{Bikesharing Data}
\subsection{Bikesharing Data}
Z
\newpage
\section{Cluster Analysis}
\subsection{Bikesharing Data}
\subsection{Bikesharing Data}
Z
\newpage
\section{Predictive Analytics}
Z
\newpage
\section{ Conclusions}
Z
\end{document}